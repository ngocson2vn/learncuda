#blocked = #ttg.blocked<{sizePerThread = [1, 16], threadsPerWarp = [16, 2], warpsPerCTA = [4, 2], order = [0, 1]}>
#loc = loc("/data03/home/son.nguyen/workspace/triton.cpp/matmul_tma_kernel.py":51:0)
#loc5 = loc("/data03/home/son.nguyen/.pyenv/versions/3.11.2/lib/python3.11/site-packages/triton/language/standard.py":41:28)
#loc16 = loc("/data03/home/son.nguyen/workspace/triton.cpp/matmul_tma_kernel.py":69:25)
#loc17 = loc("/data03/home/son.nguyen/workspace/triton.cpp/matmul_tma_kernel.py":70:22)
#loc18 = loc("/data03/home/son.nguyen/workspace/triton.cpp/matmul_tma_kernel.py":71:22)
#loc19 = loc("/data03/home/son.nguyen/workspace/triton.cpp/matmul_tma_kernel.py":78:37)
#loc20 = loc("/data03/home/son.nguyen/workspace/triton.cpp/matmul_tma_kernel.py":76:24)
#loc21 = loc("/data03/home/son.nguyen/workspace/triton.cpp/matmul_tma_kernel.py":77:24)
#loc22 = loc("/data03/home/son.nguyen/workspace/triton.cpp/matmul_tma_kernel.py":74:31)
#shared = #ttg.nvmma_shared<{swizzlingByteWidth = 128, transposed = false, elementBitWidth = 16}>
#shared1 = #ttg.nvmma_shared<{swizzlingByteWidth = 128, transposed = false, elementBitWidth = 32}>
#shared2 = #ttg.swizzled_shared<{vec = 1, perPhase = 1, maxPhase = 1, order = [0]}>
#shared3 = #ttg.nvmma_shared<{swizzlingByteWidth = 128, transposed = true, elementBitWidth = 16}>
#smem = #ttg.shared_memory
#tmem = #ttng.tensor_memory_encoding<blockM = 64, blockN = 64, unpacked = true>
#loc27 = loc("a_desc"(#loc))
#loc28 = loc("b_desc"(#loc))
#loc29 = loc("c_desc"(#loc))
#loc30 = loc("M"(#loc))
#loc31 = loc("N"(#loc))
#loc32 = loc("K"(#loc))
#loc45 = loc("k_tiles"(#loc16))
#loc46 = loc("offs_am"(#loc17))
#loc47 = loc("offs_bn"(#loc18))
#loc48 = loc("accumulator"(#loc19))
#loc49 = loc("a"(#loc20))
#loc50 = loc("b"(#loc21))
#loc51 = loc("accumulator"(#loc22))
#loc59 = loc(callsite(#loc5 at #loc45))
module attributes {"ttg.num-ctas" = 1 : i32, "ttg.num-warps" = 8 : i32, ttg.target = "cuda:100", "ttg.threads-per-warp" = 32 : i32} {
  tt.func public @matmul_kernel_tma(%a_desc: !tt.tensordesc<tensor<64x64xf16, #shared>> loc("a_desc"(#loc)), %a_desc_0: i32 loc("a_desc"(#loc)), %a_desc_1: i32 loc("a_desc"(#loc)), %a_desc_2: i64 loc("a_desc"(#loc)), %a_desc_3: i64 loc("a_desc"(#loc)), %b_desc: !tt.tensordesc<tensor<64x64xf16, #shared>> loc("b_desc"(#loc)), %b_desc_4: i32 loc("b_desc"(#loc)), %b_desc_5: i32 loc("b_desc"(#loc)), %b_desc_6: i64 loc("b_desc"(#loc)), %b_desc_7: i64 loc("b_desc"(#loc)), %c_desc: !tt.tensordesc<tensor<64x64xf32, #shared1>> loc("c_desc"(#loc)), %c_desc_8: i32 loc("c_desc"(#loc)), %c_desc_9: i32 loc("c_desc"(#loc)), %c_desc_10: i64 loc("c_desc"(#loc)), %c_desc_11: i64 loc("c_desc"(#loc)), %M: i32 {tt.divisibility = 16 : i32} loc("M"(#loc)), %N: i32 {tt.divisibility = 16 : i32} loc("N"(#loc)), %K: i32 {tt.divisibility = 16 : i32} loc("K"(#loc))) attributes {noinline = false} {
    %true = arith.constant true loc(#loc1)
    %c8_i32 = arith.constant 8 : i32 loc(#loc1)
    %c64_i32 = arith.constant 64 : i32 loc(#loc1)
    %c0_i32 = arith.constant 0 : i32 loc(#loc1)
    %c1_i32 = arith.constant 1 : i32 loc(#loc1)
    %c63_i32 = arith.constant 63 : i32 loc(#loc1)
    %cst = arith.constant dense<0.000000e+00> : tensor<64x64xf32, #blocked> loc(#loc1)
    %c2_i32 = arith.constant 2 : i32 loc(#loc1)
    %c3_i32 = arith.constant 3 : i32 loc(#loc1)
    %c4_i32 = arith.constant 4 : i32 loc(#loc1)
    %pid = tt.get_program_id x : i32 loc(#loc33)
    %num_pid_m = arith.addi %M, %c63_i32 : i32 loc(#loc54)
    %num_pid_m_12 = arith.divsi %num_pid_m, %c64_i32 : i32 loc(#loc55)
    %num_pid_n = arith.addi %N, %c63_i32 : i32 loc(#loc56)
    %num_pid_n_13 = arith.divsi %num_pid_n, %c64_i32 : i32 loc(#loc57)
    %num_pid_in_group = arith.muli %num_pid_n_13, %c8_i32 : i32 loc(#loc36)
    %group_id = arith.divsi %pid, %num_pid_in_group : i32 loc(#loc37)
    %first_pid_m = arith.muli %group_id, %c8_i32 : i32 loc(#loc38)
    %group_size_m = arith.subi %num_pid_m_12, %first_pid_m : i32 loc(#loc39)
    %group_size_m_14 = arith.minsi %group_size_m, %c8_i32 : i32 loc(#loc40)
    %pid_m = arith.remsi %pid, %group_size_m_14 : i32 loc(#loc41)
    %pid_m_15 = arith.addi %first_pid_m, %pid_m : i32 loc(#loc42)
    %pid_n = arith.remsi %pid, %num_pid_in_group : i32 loc(#loc43)
    %pid_n_16 = arith.divsi %pid_n, %group_size_m_14 : i32 loc(#loc44)
    %k_tiles = arith.addi %K, %c63_i32 : i32 loc(#loc58)
    %k_tiles_17 = arith.divsi %k_tiles, %c64_i32 : i32 loc(#loc59)
    %offs_am = arith.muli %pid_m_15, %c64_i32 : i32 loc(#loc46)
    %offs_bn = arith.muli %pid_n_16, %c64_i32 : i32 loc(#loc47)
    %accumulator = ttng.tmem_alloc : () -> !ttg.memdesc<1x64x64xf32, #tmem, #ttng.tensor_memory, mutable> loc(#loc48)
    %accumulator_18 = ttg.memdesc_index %accumulator[%c0_i32] : !ttg.memdesc<1x64x64xf32, #tmem, #ttng.tensor_memory, mutable> -> !ttg.memdesc<64x64xf32, #tmem, #ttng.tensor_memory, mutable, 1x64x64> loc(#loc48)
    ttng.tmem_store %cst, %accumulator_18, %true : tensor<64x64xf32, #blocked> -> !ttg.memdesc<64x64xf32, #tmem, #ttng.tensor_memory, mutable, 1x64x64> loc(#loc48)
    %a = ttg.local_alloc : () -> !ttg.memdesc<5x64x64xf16, #shared, #smem, mutable> loc(#loc49)
    %b = ttg.local_alloc : () -> !ttg.memdesc<5x64x64xf16, #shared, #smem, mutable> loc(#loc50)
    %accumulator_19 = ttg.local_alloc : () -> !ttg.memdesc<5x1xi64, #shared2, #smem, mutable> loc(#loc51)
    %accumulator_20 = ttg.memdesc_index %accumulator_19[%c0_i32] : !ttg.memdesc<5x1xi64, #shared2, #smem, mutable> -> !ttg.memdesc<1xi64, #shared2, #smem, mutable, 5x1> loc(#loc51)
    ttng.init_barrier %accumulator_20, 1 : !ttg.memdesc<1xi64, #shared2, #smem, mutable, 5x1> loc(#loc51)
    %accumulator_21 = ttg.memdesc_index %accumulator_19[%c1_i32] : !ttg.memdesc<5x1xi64, #shared2, #smem, mutable> -> !ttg.memdesc<1xi64, #shared2, #smem, mutable, 5x1> loc(#loc51)
    ttng.init_barrier %accumulator_21, 1 : !ttg.memdesc<1xi64, #shared2, #smem, mutable, 5x1> loc(#loc51)
    %accumulator_22 = ttg.memdesc_index %accumulator_19[%c2_i32] : !ttg.memdesc<5x1xi64, #shared2, #smem, mutable> -> !ttg.memdesc<1xi64, #shared2, #smem, mutable, 5x1> loc(#loc51)
    ttng.init_barrier %accumulator_22, 1 : !ttg.memdesc<1xi64, #shared2, #smem, mutable, 5x1> loc(#loc51)
    %accumulator_23 = ttg.memdesc_index %accumulator_19[%c3_i32] : !ttg.memdesc<5x1xi64, #shared2, #smem, mutable> -> !ttg.memdesc<1xi64, #shared2, #smem, mutable, 5x1> loc(#loc51)
    ttng.init_barrier %accumulator_23, 1 : !ttg.memdesc<1xi64, #shared2, #smem, mutable, 5x1> loc(#loc51)
    %accumulator_24 = ttg.memdesc_index %accumulator_19[%c4_i32] : !ttg.memdesc<5x1xi64, #shared2, #smem, mutable> -> !ttg.memdesc<1xi64, #shared2, #smem, mutable, 5x1> loc(#loc51)
    ttng.init_barrier %accumulator_24, 1 : !ttg.memdesc<1xi64, #shared2, #smem, mutable, 5x1> loc(#loc51)
    %accumulator_25 = ttg.local_alloc : () -> !ttg.memdesc<5x1xi64, #shared2, #smem, mutable> loc(#loc51)
    %accumulator_26 = ttg.memdesc_index %accumulator_25[%c0_i32] : !ttg.memdesc<5x1xi64, #shared2, #smem, mutable> -> !ttg.memdesc<1xi64, #shared2, #smem, mutable, 5x1> loc(#loc51)
    ttng.init_barrier %accumulator_26, 1 : !ttg.memdesc<1xi64, #shared2, #smem, mutable, 5x1> loc(#loc51)
    %accumulator_27 = ttg.memdesc_index %accumulator_25[%c1_i32] : !ttg.memdesc<5x1xi64, #shared2, #smem, mutable> -> !ttg.memdesc<1xi64, #shared2, #smem, mutable, 5x1> loc(#loc51)
    ttng.init_barrier %accumulator_27, 1 : !ttg.memdesc<1xi64, #shared2, #smem, mutable, 5x1> loc(#loc51)
    %accumulator_28 = ttg.memdesc_index %accumulator_25[%c2_i32] : !ttg.memdesc<5x1xi64, #shared2, #smem, mutable> -> !ttg.memdesc<1xi64, #shared2, #smem, mutable, 5x1> loc(#loc51)
    ttng.init_barrier %accumulator_28, 1 : !ttg.memdesc<1xi64, #shared2, #smem, mutable, 5x1> loc(#loc51)
    %accumulator_29 = ttg.memdesc_index %accumulator_25[%c3_i32] : !ttg.memdesc<5x1xi64, #shared2, #smem, mutable> -> !ttg.memdesc<1xi64, #shared2, #smem, mutable, 5x1> loc(#loc51)
    ttng.init_barrier %accumulator_29, 1 : !ttg.memdesc<1xi64, #shared2, #smem, mutable, 5x1> loc(#loc51)
    %accumulator_30 = ttg.memdesc_index %accumulator_25[%c4_i32] : !ttg.memdesc<5x1xi64, #shared2, #smem, mutable> -> !ttg.memdesc<1xi64, #shared2, #smem, mutable, 5x1> loc(#loc51)
    ttng.init_barrier %accumulator_30, 1 : !ttg.memdesc<1xi64, #shared2, #smem, mutable, 5x1> loc(#loc51)
    ttng.arrive_barrier %accumulator_20, 1 : !ttg.memdesc<1xi64, #shared2, #smem, mutable, 5x1> loc(#loc60)
    ttng.arrive_barrier %accumulator_21, 1 : !ttg.memdesc<1xi64, #shared2, #smem, mutable, 5x1> loc(#loc60)
    ttng.arrive_barrier %accumulator_22, 1 : !ttg.memdesc<1xi64, #shared2, #smem, mutable, 5x1> loc(#loc60)
    ttng.arrive_barrier %accumulator_23, 1 : !ttg.memdesc<1xi64, #shared2, #smem, mutable, 5x1> loc(#loc60)
    ttng.arrive_barrier %accumulator_24, 1 : !ttg.memdesc<1xi64, #shared2, #smem, mutable, 5x1> loc(#loc60)
    %accumulator_31 = arith.subi %k_tiles_17, %c1_i32 : i32 loc(#loc51)
    %accumulator_32 = ttg.local_alloc : () -> !ttg.memdesc<1x1xi64, #shared2, #smem, mutable> loc(#loc51)
    %accumulator_33 = ttg.memdesc_index %accumulator_32[%c0_i32] : !ttg.memdesc<1x1xi64, #shared2, #smem, mutable> -> !ttg.memdesc<1xi64, #shared2, #smem, mutable, 1x1> loc(#loc51)
    ttng.init_barrier %accumulator_33, 1 : !ttg.memdesc<1xi64, #shared2, #smem, mutable, 1x1> loc(#loc51)
    ttg.warp_specialize(%accumulator_19, %accumulator_25, %a, %b, %accumulator_31, %accumulator_18, %accumulator_33, %k_tiles_17, %a_desc, %offs_am, %b_desc, %offs_bn) attributes {requestedRegisters = array<i32: 24, 24>}
    default {
      ttg.warp_yield loc(#loc51)
    }
    partition0(%accumulator_35: !ttg.memdesc<5x1xi64, #shared2, #smem, mutable> loc("accumulator"(#loc22)), %accumulator_36: !ttg.memdesc<5x1xi64, #shared2, #smem, mutable> loc("accumulator"(#loc22)), %a_37: !ttg.memdesc<5x64x64xf16, #shared, #smem, mutable> loc("a"(#loc20)), %b_38: !ttg.memdesc<5x64x64xf16, #shared, #smem, mutable> loc("b"(#loc21)), %accumulator_39: i32 loc("accumulator"(#loc22)), %accumulator_40: !ttg.memdesc<64x64xf32, #tmem, #ttng.tensor_memory, mutable, 1x64x64> loc("accumulator"(#loc19)), %accumulator_41: !ttg.memdesc<1xi64, #shared2, #smem, mutable, 1x1> loc("accumulator"(#loc22)), %k_tiles_42: i32 loc(callsite(#loc5 at #loc45)), %a_desc_43: !tt.tensordesc<tensor<64x64xf16, #shared>> loc("a_desc"(#loc)), %offs_am_44: i32 loc("offs_am"(#loc17)), %b_desc_45: !tt.tensordesc<tensor<64x64xf16, #shared>> loc("b_desc"(#loc)), %offs_bn_46: i32 loc("offs_bn"(#loc18))) num_warps(1) {
      %c5_i32 = arith.constant 5 : i32 loc(#loc1)
      %c1_i32_47 = arith.constant 1 : i32 loc(#loc1)
      %c0_i32_48 = arith.constant 0 : i32 loc(#loc1)
      %true_49 = arith.constant true loc(#loc1)
      %false = arith.constant false loc(#loc1)
      %accumulator_50:3 = scf.for %accumulator_51 = %c0_i32_48 to %k_tiles_42 step %c1_i32_47 iter_args(%arg31 = %false, %arg32 = %c0_i32_48, %arg33 = %c0_i32_48) -> (i1, i32, i32)  : i32 {
        %accumulator_52 = ttg.memdesc_index %accumulator_35[%arg32] : !ttg.memdesc<5x1xi64, #shared2, #smem, mutable> -> !ttg.memdesc<1xi64, #shared2, #smem, mutable, 5x1> loc(#loc51)
        %accumulator_53 = ttg.memdesc_index %accumulator_36[%arg32] : !ttg.memdesc<5x1xi64, #shared2, #smem, mutable> -> !ttg.memdesc<1xi64, #shared2, #smem, mutable, 5x1> loc(#loc51)
        %a_54 = ttg.memdesc_index %a_37[%arg32] : !ttg.memdesc<5x64x64xf16, #shared, #smem, mutable> -> !ttg.memdesc<64x64xf16, #shared, #smem, mutable, 5x64x64> loc(#loc49)
        %b_55 = ttg.memdesc_index %b_38[%arg32] : !ttg.memdesc<5x64x64xf16, #shared, #smem, mutable> -> !ttg.memdesc<64x64xf16, #shared, #smem, mutable, 5x64x64> loc(#loc50)
        %accumulator_56 = ttg.memdesc_trans %b_55 {order = array<i32: 1, 0>} : !ttg.memdesc<64x64xf16, #shared, #smem, mutable, 5x64x64> -> !ttg.memdesc<64x64xf16, #shared3, #smem, mutable, 5x64x64> loc(#loc52)
        ttng.wait_barrier %accumulator_53, %arg33 : !ttg.memdesc<1xi64, #shared2, #smem, mutable, 5x1> loc(#loc60)
        %accumulator_57 = arith.cmpi eq, %accumulator_51, %accumulator_39 : i32 loc(#loc48)
        ttng.tc_gen5_mma %a_54, %accumulator_56, %accumulator_40, %arg31, %true_49, %accumulator_52[%true_49], %accumulator_41[%accumulator_57] {is_async, tt.self_latency = 1 : i32} : !ttg.memdesc<64x64xf16, #shared, #smem, mutable, 5x64x64>, !ttg.memdesc<64x64xf16, #shared3, #smem, mutable, 5x64x64>, !ttg.memdesc<64x64xf32, #tmem, #ttng.tensor_memory, mutable, 1x64x64>, !ttg.memdesc<1xi64, #shared2, #smem, mutable, 5x1>, !ttg.memdesc<1xi64, #shared2, #smem, mutable, 1x1> loc(#loc48)
        %a_58 = arith.addi %arg32, %c1_i32_47 : i32 loc(#loc60)
        %a_59 = arith.xori %arg33, %c1_i32_47 : i32 loc(#loc60)
        %a_60 = arith.cmpi eq, %a_58, %c5_i32 : i32 loc(#loc60)
        %a_61 = arith.select %a_60, %c0_i32_48, %a_58 : i32 loc(#loc60)
        %a_62 = arith.select %a_60, %a_59, %arg33 : i32 loc(#loc60)
        scf.yield %true_49, %a_61, %a_62 : i1, i32, i32 loc(#loc51)
      } {tt.warp_specialize, ttg.warp_specialize.tag = 0 : i32} loc(#loc51)
      ttg.warp_return loc(#loc51)
    }
    partition1(%accumulator_35: !ttg.memdesc<5x1xi64, #shared2, #smem, mutable> loc("accumulator"(#loc22)), %accumulator_36: !ttg.memdesc<5x1xi64, #shared2, #smem, mutable> loc("accumulator"(#loc22)), %a_37: !ttg.memdesc<5x64x64xf16, #shared, #smem, mutable> loc("a"(#loc20)), %b_38: !ttg.memdesc<5x64x64xf16, #shared, #smem, mutable> loc("b"(#loc21)), %accumulator_39: i32 loc("accumulator"(#loc22)), %accumulator_40: !ttg.memdesc<64x64xf32, #tmem, #ttng.tensor_memory, mutable, 1x64x64> loc("accumulator"(#loc19)), %accumulator_41: !ttg.memdesc<1xi64, #shared2, #smem, mutable, 1x1> loc("accumulator"(#loc22)), %k_tiles_42: i32 loc(callsite(#loc5 at #loc45)), %a_desc_43: !tt.tensordesc<tensor<64x64xf16, #shared>> loc("a_desc"(#loc)), %offs_am_44: i32 loc("offs_am"(#loc17)), %b_desc_45: !tt.tensordesc<tensor<64x64xf16, #shared>> loc("b_desc"(#loc)), %offs_bn_46: i32 loc("offs_bn"(#loc18))) num_warps(2) {
      %c5_i32 = arith.constant 5 : i32 loc(#loc1)
      %c1_i32_47 = arith.constant 1 : i32 loc(#loc1)
      %c0_i32_48 = arith.constant 0 : i32 loc(#loc1)
      %c64_i32_49 = arith.constant 64 : i32 loc(#loc1)
      %true_50 = arith.constant true loc(#loc1)
      %accumulator_51:2 = scf.for %accumulator_52 = %c0_i32_48 to %k_tiles_42 step %c1_i32_47 iter_args(%arg31 = %c0_i32_48, %arg32 = %c0_i32_48) -> (i32, i32)  : i32 {
        %offs_k = arith.muli %accumulator_52, %c64_i32_49 : i32 loc(#loc53)
        %accumulator_53 = ttg.memdesc_index %accumulator_35[%arg31] : !ttg.memdesc<5x1xi64, #shared2, #smem, mutable> -> !ttg.memdesc<1xi64, #shared2, #smem, mutable, 5x1> loc(#loc51)
        ttng.wait_barrier %accumulator_53, %arg32 : !ttg.memdesc<1xi64, #shared2, #smem, mutable, 5x1> loc(#loc60)
        %accumulator_54 = ttg.memdesc_index %accumulator_36[%arg31] : !ttg.memdesc<5x1xi64, #shared2, #smem, mutable> -> !ttg.memdesc<1xi64, #shared2, #smem, mutable, 5x1> loc(#loc51)
        ttng.barrier_expect %accumulator_54, 16384, %true_50 : !ttg.memdesc<1xi64, #shared2, #smem, mutable, 5x1> loc(#loc60)
        %a_55 = ttg.memdesc_index %a_37[%arg31] : !ttg.memdesc<5x64x64xf16, #shared, #smem, mutable> -> !ttg.memdesc<64x64xf16, #shared, #smem, mutable, 5x64x64> loc(#loc49)
        ttng.async_tma_copy_global_to_local %a_desc_43[%offs_am_44, %offs_k] %a_55, %accumulator_54, %true_50 : !tt.tensordesc<tensor<64x64xf16, #shared>>, !ttg.memdesc<1xi64, #shared2, #smem, mutable, 5x1> -> !ttg.memdesc<64x64xf16, #shared, #smem, mutable, 5x64x64> loc(#loc60)
        %b_56 = ttg.memdesc_index %b_38[%arg31] : !ttg.memdesc<5x64x64xf16, #shared, #smem, mutable> -> !ttg.memdesc<64x64xf16, #shared, #smem, mutable, 5x64x64> loc(#loc50)
        ttng.async_tma_copy_global_to_local %b_desc_45[%offs_bn_46, %offs_k] %b_56, %accumulator_54, %true_50 : !tt.tensordesc<tensor<64x64xf16, #shared>>, !ttg.memdesc<1xi64, #shared2, #smem, mutable, 5x1> -> !ttg.memdesc<64x64xf16, #shared, #smem, mutable, 5x64x64> loc(#loc60)
        %a_57 = arith.addi %arg31, %c1_i32_47 : i32 loc(#loc60)
        %a_58 = arith.xori %arg32, %c1_i32_47 : i32 loc(#loc60)
        %a_59 = arith.cmpi eq, %a_57, %c5_i32 : i32 loc(#loc60)
        %a_60 = arith.select %a_59, %c0_i32_48, %a_57 : i32 loc(#loc60)
        %a_61 = arith.select %a_59, %a_58, %arg32 : i32 loc(#loc60)
        scf.yield %a_60, %a_61 : i32, i32 loc(#loc51)
      } {tt.warp_specialize, ttg.warp_specialize.tag = 0 : i32} loc(#loc51)
      ttg.warp_return loc(#loc51)
    } : (!ttg.memdesc<5x1xi64, #shared2, #smem, mutable>, !ttg.memdesc<5x1xi64, #shared2, #smem, mutable>, !ttg.memdesc<5x64x64xf16, #shared, #smem, mutable>, !ttg.memdesc<5x64x64xf16, #shared, #smem, mutable>, i32, !ttg.memdesc<64x64xf32, #tmem, #ttng.tensor_memory, mutable, 1x64x64>, !ttg.memdesc<1xi64, #shared2, #smem, mutable, 1x1>, i32, !tt.tensordesc<tensor<64x64xf16, #shared>>, i32, !tt.tensordesc<tensor<64x64xf16, #shared>>, i32) -> () loc(#loc51)
    ttng.wait_barrier %accumulator_33, %c0_i32 : !ttg.memdesc<1xi64, #shared2, #smem, mutable, 1x1> loc(#loc48)
    ttng.inval_barrier %accumulator_33 : !ttg.memdesc<1xi64, #shared2, #smem, mutable, 1x1> loc(#loc51)
    ttg.local_dealloc %accumulator_32 : !ttg.memdesc<1x1xi64, #shared2, #smem, mutable> loc(#loc51)
    ttng.inval_barrier %accumulator_26 : !ttg.memdesc<1xi64, #shared2, #smem, mutable, 5x1> loc(#loc51)
    ttng.inval_barrier %accumulator_27 : !ttg.memdesc<1xi64, #shared2, #smem, mutable, 5x1> loc(#loc51)
    ttng.inval_barrier %accumulator_28 : !ttg.memdesc<1xi64, #shared2, #smem, mutable, 5x1> loc(#loc51)
    ttng.inval_barrier %accumulator_29 : !ttg.memdesc<1xi64, #shared2, #smem, mutable, 5x1> loc(#loc51)
    ttng.inval_barrier %accumulator_30 : !ttg.memdesc<1xi64, #shared2, #smem, mutable, 5x1> loc(#loc51)
    ttg.local_dealloc %accumulator_25 : !ttg.memdesc<5x1xi64, #shared2, #smem, mutable> loc(#loc51)
    ttng.inval_barrier %accumulator_20 : !ttg.memdesc<1xi64, #shared2, #smem, mutable, 5x1> loc(#loc51)
    ttng.inval_barrier %accumulator_21 : !ttg.memdesc<1xi64, #shared2, #smem, mutable, 5x1> loc(#loc51)
    ttng.inval_barrier %accumulator_22 : !ttg.memdesc<1xi64, #shared2, #smem, mutable, 5x1> loc(#loc51)
    ttng.inval_barrier %accumulator_23 : !ttg.memdesc<1xi64, #shared2, #smem, mutable, 5x1> loc(#loc51)
    ttng.inval_barrier %accumulator_24 : !ttg.memdesc<1xi64, #shared2, #smem, mutable, 5x1> loc(#loc51)
    ttg.local_dealloc %accumulator_19 : !ttg.memdesc<5x1xi64, #shared2, #smem, mutable> loc(#loc51)
    ttg.local_dealloc %b : !ttg.memdesc<5x64x64xf16, #shared, #smem, mutable> loc(#loc51)
    ttg.local_dealloc %a : !ttg.memdesc<5x64x64xf16, #shared, #smem, mutable> loc(#loc51)
    %accumulator_34 = ttng.tmem_load %accumulator_18 : !ttg.memdesc<64x64xf32, #tmem, #ttng.tensor_memory, mutable, 1x64x64> -> tensor<64x64xf32, #blocked> loc(#loc48)
    %0 = ttg.local_alloc %accumulator_34 : (tensor<64x64xf32, #blocked>) -> !ttg.memdesc<64x64xf32, #shared1, #smem> loc(#loc25)
    ttng.fence_async_shared {bCluster = false} loc(#loc25)
    ttng.async_tma_copy_local_to_global %c_desc[%offs_am, %offs_bn] %0 : !tt.tensordesc<tensor<64x64xf32, #shared1>>, !ttg.memdesc<64x64xf32, #shared1, #smem> loc(#loc25)
    ttng.async_tma_store_wait {pendings = 0 : i32} loc(#loc25)
    tt.return loc(#loc26)
  } loc(#loc)
} loc(#loc)
#loc1 = loc(unknown)
#loc2 = loc("/data03/home/son.nguyen/workspace/triton.cpp/matmul_tma_kernel.py":59:24)
#loc3 = loc("/data03/home/son.nguyen/.pyenv/versions/3.11.2/lib/python3.11/site-packages/triton/language/standard.py":41:22)
#loc4 = loc("/data03/home/son.nguyen/workspace/triton.cpp/matmul_tma_kernel.py":60:27)
#loc6 = loc("/data03/home/son.nguyen/workspace/triton.cpp/matmul_tma_kernel.py":61:27)
#loc7 = loc("/data03/home/son.nguyen/workspace/triton.cpp/matmul_tma_kernel.py":62:38)
#loc8 = loc("/data03/home/son.nguyen/workspace/triton.cpp/matmul_tma_kernel.py":63:22)
#loc9 = loc("/data03/home/son.nguyen/workspace/triton.cpp/matmul_tma_kernel.py":64:29)
#loc10 = loc("/data03/home/son.nguyen/workspace/triton.cpp/matmul_tma_kernel.py":65:35)
#loc11 = loc("/data03/home/son.nguyen/workspace/triton.cpp/matmul_tma_kernel.py":65:48)
#loc12 = loc("/data03/home/son.nguyen/workspace/triton.cpp/matmul_tma_kernel.py":66:33)
#loc13 = loc("/data03/home/son.nguyen/workspace/triton.cpp/matmul_tma_kernel.py":66:27)
#loc14 = loc("/data03/home/son.nguyen/workspace/triton.cpp/matmul_tma_kernel.py":67:19)
#loc15 = loc("/data03/home/son.nguyen/workspace/triton.cpp/matmul_tma_kernel.py":67:40)
#loc23 = loc("/data03/home/son.nguyen/workspace/triton.cpp/matmul_tma_kernel.py":78:32)
#loc24 = loc("/data03/home/son.nguyen/workspace/triton.cpp/matmul_tma_kernel.py":75:21)
#loc25 = loc("/data03/home/son.nguyen/workspace/triton.cpp/matmul_tma_kernel.py":82:37)
#loc26 = loc("/data03/home/son.nguyen/workspace/triton.cpp/matmul_tma_kernel.py":82:4)
#loc33 = loc("pid"(#loc2))
#loc34 = loc("num_pid_m"(#loc4))
#loc35 = loc("num_pid_n"(#loc6))
#loc36 = loc("num_pid_in_group"(#loc7))
#loc37 = loc("group_id"(#loc8))
#loc38 = loc("first_pid_m"(#loc9))
#loc39 = loc("group_size_m"(#loc10))
#loc40 = loc("group_size_m"(#loc11))
#loc41 = loc("pid_m"(#loc12))
#loc42 = loc("pid_m"(#loc13))
#loc43 = loc("pid_n"(#loc14))
#loc44 = loc("pid_n"(#loc15))
#loc52 = loc("accumulator"(#loc23))
#loc53 = loc("offs_k"(#loc24))
#loc54 = loc(callsite(#loc3 at #loc34))
#loc55 = loc(callsite(#loc5 at #loc34))
#loc56 = loc(callsite(#loc3 at #loc35))
#loc57 = loc(callsite(#loc5 at #loc35))
#loc58 = loc(callsite(#loc3 at #loc45))
#loc60 = loc(fused[#loc49, #loc50])
